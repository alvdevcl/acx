include "acxcore.conf"
play.http.secret.key = ${PLAY_HTTP_SECRET_KEY}
play.http.context = "/ac"
play.filters {
  enabled += play.filters.gzip.GzipFilter
  hosts {
    allowed = ["."]
  }
}

play.filters.csrf.header.bypassHeaders {
  Csrf-Token = "nocheck"
}

play.filters.disabled += play.filters.csrf.CSRFFilter
play.filters.disabled += play.filters.hosts.AllowedHostsFilter
play.http.errorHandler = "com.ac.util.exception.handler.ErrorHandler"
play.modules.enabled += "com.ac.authorization.AuthorizationModule"
play.modules.enabled += "play.modules.swagger.SwaggerModule"
play.modules.disabled += "play.api.db.evolutions.EvolutionsModule"
play.modules.enabled += "com.ac.bdms.persistence.evolutions.EvolutionsModule"
play.logger.includeConfigProperties = true
play.server.pidfile.path = "/dev/null"

ac.bdms {
  ac.bdms.converter.create-time-series-null-value = false
  data.service.implementation = ACServer
  data.service.prime.modelclass-in-fundmstr = true
  data.service.prime.timeseries_result_set_limit = 500
  data.loader.ado_ids_batch_size = 1000
  input.date-time-format = "yyyyMMdd'T'HHmmssZ"
  json {
    classifications.schema.file = "conf/schema/classifications-schema.json"
    domain-model.schema.file = "conf/schema/domain-model-schema.json"
    domain-view.schema.file = "conf/schema/domain-model-view.json"
    public-types.schema.file = "conf/schema/public-types-schema.json"
    domain-models-dir = "/tmp/models"
  }
  creation {
    batch-size = 100
    retry-count = 5
    use-override = true
    default-template = "BDMS_DEFAULT"
  }
  changelog.enabled = true
  changelog.max.attributes-in-record = 10
  
  # Supported property values: FILESYSTEM, ORACLE, POSTGRESQL
  configuration.store = POSTGRESQL
  applog.dir = ${?LOGS_FOLDER}
  
  pc_source_ados_attrid_default = "C0_SRC01"
  
  # BDMS instance unique identifier
  instance.id = ${?BDMS_INSTANCE_ID}
  
  # BDM data syncronization mode. The supported property values: NONE, PRIMARY, SECONDARY
  sync.mode = "NONE"
  sync.mode = ${?SYNC_MODE}
}

# default timeout for remote service response (3000 ms by default)
remote.services.timeout = ${?REMOTE_SERVICES_TIMEOUT}

# LINEAGE.ALL
remote.services.lineage-service.host = "http://data-lineage-read-service.{{ .Release.Namespace }}:9000/lineage"
remote.services.lineage-service.auth-token = ${?LINEAGE_SERVICE_AUTH_TOKEN}
remote.services.lineage-service.timeout = ${?LINEAGE_SERVICE_TIMEOUT}

# AUTHENTICATION.DATAVIEWS AUTHENTICATION.BPM AUTHENTICATION.ROLES
remote.services.auth-service.host = "http://auth-service.{{ .Release.Namespace }}:9000/auth"
remote.services.auth-service.auth-token = ${?AUTH_SERVICE_AUTH_TOKEN}
remote.services.auth-service.timeout = ${?AUTH_SERVICE_TIMEOUT}

# DCIS.ADMIN
remote.services.issue-service.host = "http://issue-service.{{ .Release.Namespace }}:9000/issue-service"
remote.services.issue-service.auth-token = ${?ISSUE_SERVICE_AUTH_TOKEN}
remote.services.issue-service.timeout = ${?ISSUE_SERVICE_TIMEOUT}

# DATASETS.ALL
remote.services.dataset-service.host = "http://data-sets-service.{{ .Release.Namespace }}:9000/datasets"
remote.services.dataset-service.auth-token = ${?DATA_SET_SERVICE_AUTH_TOKEN}
remote.services.dataset-service.timeout = ${?DATA_SET_SERVICE_TIMEOUT}

# ???
remote.services.data-processing-service.host = ${?DATA_PROCESSING_SERVICE_URL}
remote.services.data-processing-service.token = ${?DATA_PROCESSING_SERVICE_AUTH_TOKEN}
remote.services.data-processing-service.timeout = 10000

# Type mapping service URI. If not set type mapping is disabled.
remote.services.type-mapping-service.host = "http://mapping-service.{{ .Release.Namespace }}:9000/mappings"
remote.services.type-mapping-service.token = ${?MAPPING_SERVICE_AUTH_TOKEN}
remote.services.type-mapping-service.timeout = 10000

play.evolutions.autocommit = true
play.evolutions.db.bdms.enabled = true
play.evolutions.db.bdms.autoApply = true

# supported values: Prime_PostgresPersistenceUnit, Prime_OraclePersistenceUnit
jpa.prime = Prime_OraclePersistenceUnit

db.default {
  driver = oracle.jdbc.OracleDriver
  url = "jdbc:oracle:thin:@"${ORACLE_HOST}":"${ORACLE_PORT}"/"${ORACLE_DATABASE}
  logSql = true
  jndiName = PrimeDS
  username = ${ORACLE_USERNAME}
  password = ${ORACLE_PASSWORD}
}

# supported values: BDMS_PostgresPersistenceUnit, BDMS_OraclePersistenceUnit
jpa.bdms = BDMS_PostgresPersistenceUnit

db.bdms {
  driver = org.postgresql.Driver
  url = "jdbc:postgresql://"${POSTGRES_HOST}":"${POSTGRES_PORT}"/"${POSTGRES_DATABASE}
  logSql = false
  jndiName = BDMS_DS
  username = ${POSTGRES_USERNAME}
  password = ${POSTGRES_PASSWORD}
}

fixedConnectionPool = 10

# Set Hikari to fixed size
play.db {
  prototype {
    hikaricp.minimumIdle = ${fixedConnectionPool}
    hikaricp.maximumPoolSize = ${fixedConnectionPool}
    hikaricp.idleTimeout = 60000
    hikaricp.connectionTimeout = 60000
    hikaricp.validationTimeout = 3000
    hikaricp.loginTimeout = 5
    hikaricp.maxLifetime = 60000
  }
}

contexts {
  # Thread context for data service (Prime or ACX) queries
  dataServiceQueryOperations {
    executor = "thread-pool-executor"
    throughput = 1
    thread-pool-executor {
      fixed-pool-size = 10
    }
  }
  
  # Thread context for attribute value queries (Prime or ACX)
  attributeValueQueryOperations {
    executor = "thread-pool-executor"
    throughput = 1
    thread-pool-executor {
      fixed-pool-size = 20
    }
  }
  
  # Thread context for attribute value updates (Prime or ACX)
  attributeValueUpdateOperations {
    executor = "thread-pool-executor"
    throughput = 1
    thread-pool-executor {
      fixed-pool-size = 10
    }
  }
  
  # Thread context for data export (e.g. Excel)
  dataExport {
    executor = "thread-pool-executor"
    throughput = 1
    thread-pool-executor {
      fixed-pool-size = 2
      fixed-pool-size = ${?DATA_EXPORT_THREAD_POOL_SIZE}
    }
  }
}

ac.api {
  host = ${PRIME_HOST}
  installation = ${PRIME_INSTALLATION}
  user = ${PRIME_USERNAME}
  password = ${PRIME_PASSWORD}
  queriesMax = 4
  retryInitialInterval = ${?AC_CONNECTION_RETRY_INITIAL_INTERVAL}
  retryMaxAttempts = ${?AC_CONNECTION_RETRY_MAX_ATTEMPTS}
}

ac.authentication {
  enabled = false
  keystore.file = "conf/keystore.jks"
  keystore.password = ${KEYSTORE_PASSWORD}
  key.alias = ${KEYSTORE_KEY_ALIAS}
  key.password = ${KEYSTORE_KEY_PASSWORD}
  cipher.algorithm = ${KEYSTORE_SIG_ALG}
  rights.cookie.name = "rights"
  password.expiration.enabled = false
  rights.expiration.enabled = false
}

akka.http {
  parsing {
    max-uri-length = 1m
  }
}

play.server.akka.max-header-value-length = 1M
play.http.parser.maxMemoryBuffer = 20MB
play.http.parser.maxDiskBuffer = 200MB
parsers.anyContent.maxLength = 200MB

swagger {
  filter = "com.ac.bdms.ws.swagger.SwaggerDefaultApiSpecFilter"
  api {
    host = "ops360.rdm.aws-dev.capgroup.com/ac"
    info {
      title = "BDMS API"
      license = "Copyrights: Asset Control International B.V."
      licenseUrl = "https://www.asset-control.com"
    }
  }
}

kafka {
  broker = ${?KAFKA_BROKER}
  groupId = "bdms_model_update_consumer_"
  model-updates-topic = "bdms-model-updates"
  type-mapping-updates-topic = "type-mapping-updates"
}

secret.name.prefix = "bdms-secret."
secret.name.prefix = ${?SECRET_PREFIX}
secrets.dir = /dev/null

play.application.loader = com.ac.bdms.config.BDMSApplicationLoader
play.application.config_providers = ["com.ac.bdms.config.BDMSConditionalConfigProvider"]
swagger.filter = "com.ac.bdms.swagger.CustomSpecFilter"
